{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#syntax = \"proto3\";\n",
    "#\n",
    "#package tensorflow;\n",
    "#option cc_enable_arenas = true;\n",
    "#option java_outer_classname = \"StepStatsProtos\";\n",
    "#option java_multiple_files = true;\n",
    "#option java_package = \"org.tensorflow.framework\";\n",
    "#option go_package = \"github.com/tensorflow/tensorflow/tensorflow/go/core/framework\";\n",
    "#import \"tensorflow/core/framework/allocation_description.proto\";\n",
    "#import \"tensorflow/core/framework/tensor_description.proto\";\n",
    "#\n",
    "#// An allocation/de-allocation operation performed by the allocator.\n",
    "#message AllocationRecord {\n",
    "#  // The timestamp of the operation.\n",
    "#  int64 alloc_micros = 1;\n",
    "#  // Number of bytes allocated, or de-allocated if negative.\n",
    "#  int64 alloc_bytes = 2;\n",
    "#}\n",
    "#\n",
    "#message AllocatorMemoryUsed {\n",
    "#  string allocator_name = 1;\n",
    "#  // These are per-node allocator memory stats.\n",
    "#  int64 total_bytes = 2;\n",
    "#  int64 peak_bytes = 3;\n",
    "#  // The bytes that are not deallocated.\n",
    "#  int64 live_bytes = 4;\n",
    "#  // The allocation and deallocation timeline.\n",
    "#  repeated AllocationRecord allocation_records = 6;\n",
    "#\n",
    "#  // These are snapshots of the overall allocator memory stats.\n",
    "#  // The number of live bytes currently allocated by the allocator.\n",
    "#  int64 allocator_bytes_in_use = 5;\n",
    "#}\n",
    "#\n",
    "#// Output sizes recorded for a single execution of a graph node.\n",
    "#message NodeOutput {\n",
    "#  int32 slot = 1;\n",
    "#  TensorDescription tensor_description = 3;\n",
    "#};\n",
    "#\n",
    "#// For memory tracking.\n",
    "#message MemoryStats {\n",
    "#  int64 temp_memory_size = 1;\n",
    "#  int64 persistent_memory_size = 3;\n",
    "#  repeated int64 persistent_tensor_alloc_ids = 5;\n",
    "#\n",
    "#  int64 device_temp_memory_size = 2 [deprecated = true];\n",
    "#  int64 device_persistent_memory_size = 4 [deprecated = true];\n",
    "#  repeated int64 device_persistent_tensor_alloc_ids = 6 [deprecated = true];\n",
    "#}\n",
    "#\n",
    "#// Time/size stats recorded for a single execution of a graph node.\n",
    "#message NodeExecStats {\n",
    "#  // TODO(tucker): Use some more compact form of node identity than\n",
    "#  // the full string name.  Either all processes should agree on a\n",
    "#  // global id (cost_id?) for each node, or we should use a hash of\n",
    "#  // the name.\n",
    "#  string node_name = 1;\n",
    "#  int64 all_start_micros = 2;\n",
    "#  int64 op_start_rel_micros = 3;\n",
    "#  int64 op_end_rel_micros = 4;\n",
    "#  int64 all_end_rel_micros = 5;\n",
    "#  repeated AllocatorMemoryUsed memory = 6;\n",
    "#  repeated NodeOutput output = 7;\n",
    "#  string timeline_label = 8;\n",
    "#  int64 scheduled_micros = 9;\n",
    "#  uint32 thread_id = 10;\n",
    "#  repeated AllocationDescription referenced_tensor = 11;\n",
    "#  MemoryStats memory_stats = 12;\n",
    "#  int64 all_start_nanos = 13;\n",
    "#  int64 op_start_rel_nanos = 14;\n",
    "#  int64 op_end_rel_nanos = 15;\n",
    "#  int64 all_end_rel_nanos = 16;\n",
    "#  int64 scheduled_nanos = 17;\n",
    "#};\n",
    "#\n",
    "#message DeviceStepStats {\n",
    "#  string device = 1;\n",
    "#  repeated NodeExecStats node_stats = 2;\n",
    "#}\n",
    "#\n",
    "#message StepStats {\n",
    "#  repeated DeviceStepStats dev_stats = 1;\n",
    "#};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Views:\n",
    "    * graph view\n",
    "    * scope view\n",
    "    * op view\n",
    "    * code view\n",
    "Output format:\n",
    "    * timeline json\n",
    "    * stdout\n",
    "    * pprof file\n",
    "    * txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import mnist\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "from tensorflow.python.profiler import model_analyzer\n",
    "from tensorflow.python.profiler import option_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS:\n",
    "  def __init__(self):\n",
    "    self.hidden1_dim =128     #hidden1 layer 的维度\n",
    "    self.hidden2_dim = 32     #hidden2 layer 的维度\n",
    "    self.learning_rate = 1e-2\n",
    "    self.batch_size = 100\n",
    "    self.max_step = 100        # 最大的训练步骤\n",
    "    self.stats_per_steps = 10  # 每隔10步搜集一次RunMetadata。 可以根据需要修改\n",
    "    self.data_set_dir =  '' #替换为你的本地mnist数据集路径，如果你已经下载过\n",
    "\n",
    "\n",
    "TRAINING_FLAGS = FLAGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-c42235aa5943>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/zhangzining/.virtualenvs/tacotron/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/zhangzining/.virtualenvs/tacotron/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/zhangzining/.virtualenvs/tacotron/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/zhangzining/.virtualenvs/tacotron/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/zhangzining/.virtualenvs/tacotron/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "data_sets = input_data.read_data_sets(train_dir=TRAINING_FLAGS.data_set_dir,fake_data=False)\n",
    "images_placeholder = tf.placeholder(tf.float32, shape=(TRAINING_FLAGS.batch_size,\n",
    "                                                       mnist.IMAGE_PIXELS))\n",
    "labels_placeholder = tf.placeholder(tf.int32, shape=(TRAINING_FLAGS.batch_size))\n",
    "\n",
    "logits = mnist.inference(images_placeholder,\n",
    "                         TRAINING_FLAGS.hidden1_dim,\n",
    "                         TRAINING_FLAGS.hidden2_dim)\n",
    "loss = mnist.loss(logits, labels_placeholder)\n",
    "train_op = mnist.training(loss, TRAINING_FLAGS.learning_rate)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_profiler = model_analyzer.Profiler(graph=sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_options = tf.RunOptions(trace_level = tf.RunOptions.FULL_TRACE) #hardware + software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_metadata = tf.RunMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = dict()\n",
    "for step in range(TRAINING_FLAGS.max_step):\n",
    "    images_feed, labels_feed = data_sets.train.next_batch(TRAINING_FLAGS.batch_size, fake_data=False)\n",
    "    feed_dict = {\n",
    "                 images_placeholder: images_feed,\n",
    "                 labels_placeholder: labels_feed,\n",
    "                }    \n",
    "    if step % TRAINING_FLAGS.stats_per_steps == 0:\n",
    "        _, loss_value = sess.run(fetches=[train_op, loss],feed_dict=feed_dict, options=run_options, run_metadata=run_metadata)\n",
    "\n",
    "        #将本步搜集的统计数据添加到tfprofiler实例中     \n",
    "        mnist_profiler.add_step(step=step, run_meta=run_metadata)\n",
    "    else:\n",
    "        _, loss_value = sess.run(fetches=[train_op, loss],\n",
    "                               feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_options = {'max_depth': 100,\n",
    "            'min_bytes': 0,\n",
    "            'min_micros': 0,\n",
    "            'min_params': 0,\n",
    "            'min_float_ops': 0,\n",
    "            'min_occurrence': 0,\n",
    "            'order_by': 'name',\n",
    "            'account_type_regexes': ['.*'],\n",
    "            'start_name_regexes': ['.*'],\n",
    "            'trim_name_regexes': [],\n",
    "            'show_name_regexes': ['.*'],\n",
    "            'hide_name_regexes': [],\n",
    "            'account_displayed_op_only': False,\n",
    "            'select': ['micros'],\n",
    "            'step': -1,#average of all\n",
    "            'output': 'stdout'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "checkers {\n",
       "  key: \"AcceleratorUtilizationChecker\"\n",
       "  value {\n",
       "  }\n",
       "}\n",
       "checkers {\n",
       "  key: \"ExpensiveOperationChecker\"\n",
       "  value {\n",
       "    reports: \"top 1 operation type: MatMul, cpu: 604us, accelerator: 0us, total: 604us (50.80%)\\ntop 2 operation type: ApplyGradientDescent, cpu: 153us, accelerator: 0us, total: 153us (12.87%)\\ntop 3 operation type: SparseSoftmaxCrossEntropyWithLogits, cpu: 146us, accelerator: 0us, total: 146us (12.28%)\"\n",
       "    reports: \"top 1 graph node: hidden1, cpu: 0us, accelerator: 0us, total: 0us\\ntop 2 graph node: gradients, cpu: 0us, accelerator: 0us, total: 0us\\ntop 3 graph node: GradientDescent, cpu: 43us, accelerator: 0us, total: 43us\"\n",
       "    reports: \"\"\n",
       "  }\n",
       "}\n",
       "checkers {\n",
       "  key: \"OperationChecker\"\n",
       "  value {\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 options dicts\n",
    "#trainable_variables_parameter()\n",
    "#float_operations()\n",
    "#time_and_memory()\n",
    "\n",
    "profile_graph_opts_builder = option_builder.ProfileOptionBuilder()\n",
    "#option_builder.ProfileOptionBuilder.trainable_variables_parameter())\n",
    "\n",
    "#output method1\n",
    "#profile_graph_opts_builder.with_timeline_output(timeline_file='/tmp/mnist_profiler.json')\n",
    "profile_graph_opts_builder.with_file_output(outfile='abc.txt')\n",
    "\n",
    "#display options\n",
    "#profile_graph_opts_builder.with_accounted_type_regexes('')# ‘.MatMul.‘, ‘.*Conv2D’, ‘.*gpu:0’\n",
    "#profile_graph_opts_builder.with_node_names(show_name_regexes=['*'])\n",
    "\n",
    "#setters start with 'with'\n",
    "profile_graph_opts_builder.with_step(70)\n",
    "profile_graph_opts_builder.with_max_depth(20)\n",
    "profile_graph_opts_builder.account_displayed_op_only(True)\n",
    "\n",
    "#query\n",
    "profile_graph_opts_builder.select(['micros', 'occurrence'])\n",
    "profile_graph_opts_builder.order_by('micros')\n",
    "\n",
    "\n",
    "#view type1\n",
    "mnist_profiler.profile_graph(profile_graph_opts_builder.build())\n",
    "\n",
    "##view type2\n",
    "#mnist_profiler.profile_name_scope(profile_graph_opts_builder.build())\n",
    "#\n",
    "##view type3\n",
    "#mnist_profiler.profile_operations(profile_graph_opts_builder.build())\n",
    "#\n",
    "##view type4\n",
    "#mnist_profiler.profile_python(profile_graph_opts_builder.build())\n",
    "\n",
    "#advise\n",
    "mnist_profiler.advise(options=model_analyzer.ALL_ADVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
